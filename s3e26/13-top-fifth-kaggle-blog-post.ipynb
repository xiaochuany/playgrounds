{
 "cells": [
  {
   "cell_type": "raw",
   "id": "292008e0-85b2-43f1-b9a3-52453b4dba52",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"What is required to achieve a top 20% ranking in Kaggle playground series\"\n",
    "author: \"Xiaochuan Yang\"\n",
    "date: \"2023-12-16\"\n",
    "categories: [kaggle, python, machine learning]\n",
    "draft: false\n",
    "toc: true\n",
    "number-sections: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cd3258-31dd-438d-aba0-753a41af314d",
   "metadata": {},
   "source": [
    "The playground series is devoted to tabular datasets and are the most accessible competitions for beginners to learn and develop skills. This blog/notebook is to showcase some streamlined approach to achieve a relatively good performance. The notebook is written for Kaggle playground series season 3 episode 26 (last one in 2023). At the time of writing this blog, the submission achieves 149/871 (top 18%) ranking.  \n",
    "\n",
    "Outline: \n",
    "\n",
    "- use `fastkaggle` module to quickly set up the competition (download and unzip data) and submit it later. \n",
    "- preprocess data: add additional dataset offered by the competition owner\n",
    "- modelling: compute cv score of \n",
    "    - base models: logistic regression, random forest (not supporting `np.nan`)\n",
    "    - gradient boosting: hist gradient boosting, light gbm, xgboost\n",
    "- cross validate the best model (lgbm), return classifiers and average out the predictions on test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f09f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install fastkaggle if not available\n",
    "try: import fastkaggle\n",
    "except ModuleNotFoundError:\n",
    "    !pip install -Uq fastkaggle\n",
    "\n",
    "from fastkaggle import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f21256",
   "metadata": {},
   "source": [
    "## Getting set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2d75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading playground-series-s3e26.zip to /home/xy/git/1principle/posts/gist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 350k/350k [00:00<00:00, 1.56MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "comp = 'playground-series-s3e26'\n",
    "path = setup_comp(comp, install='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f9000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('playground-series-s3e26')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e2512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7905 entries, 0 to 7904\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             7905 non-null   int64  \n",
      " 1   N_Days         7905 non-null   int64  \n",
      " 2   Drug           7905 non-null   object \n",
      " 3   Age            7905 non-null   int64  \n",
      " 4   Sex            7905 non-null   object \n",
      " 5   Ascites        7905 non-null   object \n",
      " 6   Hepatomegaly   7905 non-null   object \n",
      " 7   Spiders        7905 non-null   object \n",
      " 8   Edema          7905 non-null   object \n",
      " 9   Bilirubin      7905 non-null   float64\n",
      " 10  Cholesterol    7905 non-null   float64\n",
      " 11  Albumin        7905 non-null   float64\n",
      " 12  Copper         7905 non-null   float64\n",
      " 13  Alk_Phos       7905 non-null   float64\n",
      " 14  SGOT           7905 non-null   float64\n",
      " 15  Tryglicerides  7905 non-null   float64\n",
      " 16  Platelets      7905 non-null   float64\n",
      " 17  Prothrombin    7905 non-null   float64\n",
      " 18  Stage          7905 non-null   float64\n",
      " 19  Status         7905 non-null   object \n",
      "dtypes: float64(10), int64(3), object(7)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "trn_path = path/'train.csv'\n",
    "trn = pd.read_csv(trn_path)\n",
    "trn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9042800-ae5c-4df8-a27f-f15ce3a903c4",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199ddfda-36a7-4c1e-92b9-4da9370ebe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset(path, 'joebeachcapital/cirrhosis-patient-survival-prediction', force=True) # filename= cirrhosis.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293552a4-dca8-4d23-a02b-29ed926bd31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, train=True, dropna=False):\n",
    "    df_ = df.copy()\n",
    "    df_['is_gen']='Y'\n",
    "    if train:\n",
    "        df1 = pd.read_csv(path/'cirrhosis.csv') # original data based on which the dataset is synthesized\n",
    "        df1 = pd.concat([df1.drop('Status', axis=1), df1['Status']], axis=1) # move status to last col, same as df_\n",
    "        df1['is_gen']='N'\n",
    "        df1.columns = df_.columns\n",
    "        df_ = pd.concat([df_,df1], axis=0).reset_index(drop=True)\n",
    "        if dropna: df_=df_.dropna()\n",
    "        df_['Status']= df_.Status.map({'C':0, 'CL':1,'D':2})\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c42628-a3e1-409a-88be-fa228f929f3e",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eef354-27a0-4f22-8ded-70b3e8ff0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,PowerTransformer,LabelEncoder\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold, cross_val_score, cross_validate, KFold\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, classification_report, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from scipy.stats import loguniform\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2503ff0c-828c-4a81-b050-a87c1574f3ad",
   "metadata": {},
   "source": [
    "### models not supporting nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8591976-2dba-4970-b929-c276b66607eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess(pd.read_csv(trn_path),train=True, dropna=True)\n",
    "X, y = df.drop('Status', axis=1).iloc[:,1:], df['Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d4662-b9f8-46cf-af65-242828e6f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "                (PowerTransformer(), make_column_selector(dtype_include = np.number)),\n",
    "                (OneHotEncoder(drop='if_binary', handle_unknown='ignore'), make_column_selector(dtype_include=object)), \n",
    "                remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e54ad7-cce2-4955-afe5-79c439a57d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xy/miniforge3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [6] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logitstic regression -logit_cv.mean()=0.5110572273752632\n",
      "CPU times: user 92.2 ms, sys: 20.3 ms, total: 113 ms\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit_cv =cross_val_score(\n",
    "    make_pipeline(ct, LogisticRegression(max_iter=1000)),\n",
    "    X,y, scoring = 'neg_log_loss', cv=10, n_jobs=-1)\n",
    "print(f'logitstic regression {-logit_cv.mean()=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de18f8-346b-4cf3-8f73-a5da9f05cef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forrest -RF_cv.mean()=0.44559989137605854\n",
      "CPU times: user 2min 23s, sys: 33.3 s, total: 2min 56s\n",
      "Wall time: 48.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RF_cv = cross_val_score(make_pipeline(ct, RandomForestClassifier(**{'n_estimators': 1000,\n",
    "                                                  'criterion': 'log_loss',\n",
    "                                                  'max_depth': 14,\n",
    "                                                  'min_samples_split': 3,\n",
    "                                                  'min_samples_leaf': 1,\n",
    "                                                  'max_features': 4,\n",
    "                                                  'random_state': 1,\n",
    "                                                  'n_jobs': -1})),\n",
    "                        X, y, scoring = 'neg_log_loss', cv = 10, n_jobs=-1)\n",
    "print(f\"random forrest {-RF_cv.mean()=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0cb286-51ed-4148-8868-48001cba2373",
   "metadata": {},
   "source": [
    "### models supporting nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d86bf0-fa85-4166-a09e-1624dfa7f5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess(pd.read_csv(trn_path),train=True, dropna=False)\n",
    "X, y = df.drop('Status', axis=1).iloc[:,1:], df['Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07267b-8dd3-495b-a7af-04c664df6e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xy/miniforge3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [0, 2, 3, 4, 6] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histGB -HB_cv.mean()=0.43771002014457927\n",
      "CPU times: user 162 ms, sys: 118 ms, total: 281 ms\n",
      "Wall time: 15.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "HB_cv = cross_val_score(make_pipeline(ct, HistGradientBoostingClassifier(**{'l2_regularization': 8.876168706639714,\n",
    "                                                          'early_stopping': False,\n",
    "                                                          'learning_rate': 0.009956485590638034,\n",
    "                                                          'max_iter': 500,\n",
    "                                                          'max_depth': 16,\n",
    "                                                          'max_bins': 255,\n",
    "                                                          'min_samples_leaf': 16,\n",
    "                                                          'max_leaf_nodes': 18,\n",
    "                                                          'random_state': 3})),\n",
    "                        X, y, scoring = 'neg_log_loss', cv = 10, n_jobs = -1)\n",
    "\n",
    "print(f\"histGB {-HB_cv.mean()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afdfb88-9a33-444d-b9f5-b3b6055fd93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "LGBM_cv = cross_val_score(make_pipeline(ct,LGBMClassifier(**{'n_estimators': 1000,\n",
    "                                            'learning_rate': 0.013657589160895923,\n",
    "                                            'max_depth': 17,\n",
    "                                            'reg_alpha': 1.9791969860931342,\n",
    "                                            'reg_lambda': 1.2857088172765347,\n",
    "                                            'num_leaves': 37,\n",
    "                                            'subsample': 0.6351453342675659,\n",
    "                                            'colsample_bytree': 0.2644509924064132})),\n",
    "                          X, y, scoring = 'neg_log_loss', cv = 10, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4ee7b2-5c1f-492c-8b38-ca1ab7b950ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light GBM  -LGBM_cv.mean()=0.42275781396747264\n"
     ]
    }
   ],
   "source": [
    "print(f\"Light GBM  {-LGBM_cv.mean()=}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e3d83f-2f18-45a9-b66c-3a84581f1392",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "XGB_cv = cross_val_score(make_pipeline(ct, XGBClassifier(**{'max_depth': 7,\n",
    "                                          'learning_rate': 0.03570188608151033,\n",
    "                                          'n_estimators': 1000,\n",
    "                                          'gamma': 0.6440001307764849,\n",
    "                                          'min_child_weight': 2,\n",
    "                                          'colsample_bytree': 0.27034458854562116,\n",
    "                                          'subsample': 0.8435412915999765})), \n",
    "                          X, y, scoring = 'neg_log_loss', cv = 10, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a58b8-777a-482e-9516-1198e8d0edce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost -XGB_cv.mean()=0.42872410511564896\n"
     ]
    }
   ],
   "source": [
    "print(f\"XGBoost {-XGB_cv.mean()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca6b1cb-c469-4743-94bd-1b1a0b72d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(X,y,cv=10):\n",
    "    clf = LGBMClassifier(**{'n_estimators': 1000,\n",
    "                            'learning_rate': 0.013657589160895923,\n",
    "                            'max_depth': 17,\n",
    "                            'reg_alpha': 1.9791969860931342,\n",
    "                            'reg_lambda': 1.2857088172765347,\n",
    "                            'num_leaves': 37,\n",
    "                            'subsample': 0.6351453342675659,\n",
    "                            'colsample_bytree': 0.2644509924064132})\n",
    "    ct = make_column_transformer(\n",
    "                (PowerTransformer(), make_column_selector(dtype_include = np.number)),\n",
    "                (OneHotEncoder(drop='if_binary', handle_unknown='ignore'), make_column_selector(dtype_include=object)), \n",
    "                remainder = 'passthrough')\n",
    "    model = make_pipeline(ct, clf)\n",
    "    return cross_validate(model, X, y, cv=cv, scoring='neg_log_loss', return_estimator=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b9ab8d-ca32-48e6-8dcd-89df62739e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cv_output = cv(X,y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1ddd0-075c-480e-a5d2-a12d863611e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-cv_output['test_score'].mean()=0.4206909352553819, cv_output['test_score'].std()=0.04075158479629894\n"
     ]
    }
   ],
   "source": [
    "print(f\"{-cv_output['test_score'].mean()=}, {cv_output['test_score'].std()=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab26601",
   "metadata": {},
   "source": [
    "## Submitting to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd25e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Status_C</th>\n",
       "      <th>Status_CL</th>\n",
       "      <th>Status_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7905</td>\n",
       "      <td>0.628084</td>\n",
       "      <td>0.034788</td>\n",
       "      <td>0.337128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7906</td>\n",
       "      <td>0.628084</td>\n",
       "      <td>0.034788</td>\n",
       "      <td>0.337128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7907</td>\n",
       "      <td>0.628084</td>\n",
       "      <td>0.034788</td>\n",
       "      <td>0.337128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7908</td>\n",
       "      <td>0.628084</td>\n",
       "      <td>0.034788</td>\n",
       "      <td>0.337128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7909</td>\n",
       "      <td>0.628084</td>\n",
       "      <td>0.034788</td>\n",
       "      <td>0.337128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  Status_C  Status_CL  Status_D\n",
       "0  7905  0.628084   0.034788  0.337128\n",
       "1  7906  0.628084   0.034788  0.337128\n",
       "2  7907  0.628084   0.034788  0.337128\n",
       "3  7908  0.628084   0.034788  0.337128\n",
       "4  7909  0.628084   0.034788  0.337128"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = pd.read_csv(path/'sample_submission.csv')\n",
    "ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c32e1-a7cc-43b7-ac8b-cc0a8a5c8fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>N_Days</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Hepatomegaly</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Alk_Phos</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Tryglicerides</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Prothrombin</th>\n",
       "      <th>Stage</th>\n",
       "      <th>is_gen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7905</td>\n",
       "      <td>3839</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>19724</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.2</td>\n",
       "      <td>546.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1636.0</td>\n",
       "      <td>151.90</td>\n",
       "      <td>90.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7906</td>\n",
       "      <td>2468</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>14975</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>151.90</td>\n",
       "      <td>155.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7907</td>\n",
       "      <td>51</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>13149</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>2.96</td>\n",
       "      <td>46.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>69.75</td>\n",
       "      <td>101.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7908</td>\n",
       "      <td>2330</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>20510</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.6</td>\n",
       "      <td>293.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>40.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>125.55</td>\n",
       "      <td>56.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7909</td>\n",
       "      <td>1615</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>21904</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.4</td>\n",
       "      <td>277.0</td>\n",
       "      <td>2.97</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>125.00</td>\n",
       "      <td>126.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  N_Days             Drug    Age Sex Ascites Hepatomegaly Spiders  \\\n",
       "0  7905    3839  D-penicillamine  19724   F       N            Y       N   \n",
       "1  7906    2468  D-penicillamine  14975   F       N            N       N   \n",
       "2  7907      51          Placebo  13149   F       N            Y       N   \n",
       "3  7908    2330  D-penicillamine  20510   F       N            N       N   \n",
       "4  7909    1615  D-penicillamine  21904   F       N            Y       N   \n",
       "\n",
       "  Edema  Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  \\\n",
       "0     N        1.2        546.0     3.37    65.0    1636.0  151.90   \n",
       "1     N        1.1        660.0     4.22    94.0    1257.0  151.90   \n",
       "2     Y        2.0        151.0     2.96    46.0     961.0   69.75   \n",
       "3     N        0.6        293.0     3.85    40.0     554.0  125.55   \n",
       "4     N        1.4        277.0     2.97   121.0    1110.0  125.00   \n",
       "\n",
       "   Tryglicerides  Platelets  Prothrombin  Stage is_gen  \n",
       "0           90.0      430.0         10.6    2.0      Y  \n",
       "1          155.0      227.0         10.0    2.0      Y  \n",
       "2          101.0      213.0         13.0    4.0      Y  \n",
       "3           56.0      270.0         10.6    2.0      Y  \n",
       "4          126.0      221.0          9.8    1.0      Y  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = preprocess(pd.read_csv(path/'test.csv'), train=False)\n",
    "tst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48406c30-8f65-41e2-89d9-b7d888179b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_pred = np.stack([est.predict_proba(tst.iloc[:,1:]) for est in cv_output['estimator']]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d57bd-d75a-4936-a374-6ec7f1a4611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.iloc[:,1:] = tst_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35172dac-97be-425c-b3db-a73e7950e2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,Status_C,Status_CL,Status_D\n",
      "7905,0.3034480206600728,0.02175049687406757,0.6748014824658597\n",
      "7906,0.464722990035046,0.17105995489987008,0.3642170550650838\n",
      "7907,0.034054616093133115,0.011479074721858778,0.954466309185008\n",
      "7908,0.9778662946803056,0.002733559845527006,0.01940014547416722\n",
      "7909,0.8730251010963693,0.042703149687327954,0.08427174921630272\n",
      "7910,0.9909153131787145,0.0011266786376778267,0.007958008183607803\n",
      "7911,0.9843376622366685,0.0014776242979965683,0.014184713465334847\n",
      "7912,0.0945863204842192,0.026772389955302976,0.8786412895604778\n",
      "7913,0.009370330198415863,0.0019239529424342871,0.98870571685915\n"
     ]
    }
   ],
   "source": [
    "ss.to_csv('subm.csv', index=False)\n",
    "!head subm.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not iskaggle:\n",
    "    from kaggle import api\n",
    "    api.competition_submit_cli('subm.csv', 'lgbm 10fold avg', comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04efcc0",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The hypterparameters for each model should be found before hand with e.g. `optuna`. Here we copy those from this excellent [notebook](https://github.com/oscarm524/Kaggle_Notebooks/blob/0ed35829e79eb1d7a37ed4410072c738008ee042/ps-s3-ep26-eda-modeling-submission.ipynb). \n",
    "Note however that the ensemble method adopted here is less sophisticated than the said notebook, the purpose of which is to reach a reasonable place faster. \n",
    "\n",
    "Apart from careful ensemble (such as weighted average), it would be useful to exploit/create more predictive features. Some domain knowledge might come in handy. \n",
    "\n",
    "A different direction is to replace tree-based models by neural nets. This is worth another post and hopefully I will come back to it soon.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e901eb-2691-4216-a8f5-014ad9ea96f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
