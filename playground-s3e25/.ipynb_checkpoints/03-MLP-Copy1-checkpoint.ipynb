{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "732f09f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install fastkaggle if not available\n",
    "try: import fastkaggle\n",
    "except ModuleNotFoundError:\n",
    "    !pip install -Uq fastkaggle\n",
    "\n",
    "from fastkaggle import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f21256",
   "metadata": {},
   "source": [
    "## Getting set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f2d75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = 'playground-series-s3e25'\n",
    "path = setup_comp(comp, install='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879f9000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('playground-series-s3e25')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c8e2512",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_path = path/'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cef33d49-efc7-49ce-9ce1-c8d5e9fbcb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "from fastai.data.all import *\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(trn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5365203-c372-4555-b4d0-72f5b71c58a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.841611</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>20.612526</td>\n",
       "      <td>11.088100</td>\n",
       "      <td>2.766000</td>\n",
       "      <td>1.732000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.496070</td>\n",
       "      <td>0.91457</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.558488</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>20.298893</td>\n",
       "      <td>12.040830</td>\n",
       "      <td>2.755000</td>\n",
       "      <td>1.631000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.492719</td>\n",
       "      <td>0.71760</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>76.0</td>\n",
       "      <td>8.885992</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>33.739258</td>\n",
       "      <td>12.086300</td>\n",
       "      <td>2.828000</td>\n",
       "      <td>1.788000</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.481478</td>\n",
       "      <td>1.50633</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.795296</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>20.213349</td>\n",
       "      <td>10.948500</td>\n",
       "      <td>2.648000</td>\n",
       "      <td>1.626000</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.489272</td>\n",
       "      <td>0.78937</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>9.577996</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>24.988133</td>\n",
       "      <td>11.824480</td>\n",
       "      <td>2.766000</td>\n",
       "      <td>1.682000</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.492736</td>\n",
       "      <td>1.86481</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10402</th>\n",
       "      <td>10402</td>\n",
       "      <td>128.0</td>\n",
       "      <td>7.558488</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>26.385218</td>\n",
       "      <td>11.330440</td>\n",
       "      <td>2.644000</td>\n",
       "      <td>1.631000</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.496070</td>\n",
       "      <td>1.79607</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10403</th>\n",
       "      <td>10403</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.743160</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>20.766935</td>\n",
       "      <td>14.163933</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>1.556667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.480390</td>\n",
       "      <td>0.81480</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10404</th>\n",
       "      <td>10404</td>\n",
       "      <td>196.0</td>\n",
       "      <td>30.920000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>53.490297</td>\n",
       "      <td>10.074300</td>\n",
       "      <td>2.295000</td>\n",
       "      <td>1.545000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>0.469715</td>\n",
       "      <td>2.11540</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>10405</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.553160</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>26.621687</td>\n",
       "      <td>11.290033</td>\n",
       "      <td>2.743333</td>\n",
       "      <td>1.756667</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.486507</td>\n",
       "      <td>0.77755</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10406</th>\n",
       "      <td>10406</td>\n",
       "      <td>288.0</td>\n",
       "      <td>24.655328</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>22.536126</td>\n",
       "      <td>10.960357</td>\n",
       "      <td>2.792143</td>\n",
       "      <td>1.772857</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.493919</td>\n",
       "      <td>0.97737</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10407 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  allelectrons_Total  density_Total  allelectrons_Average  \\\n",
       "0          0               100.0       0.841611             10.000000   \n",
       "1          1               100.0       7.558488             10.000000   \n",
       "2          2                76.0       8.885992             15.600000   \n",
       "3          3               100.0       8.795296             10.000000   \n",
       "4          4               116.0       9.577996             11.600000   \n",
       "...      ...                 ...            ...                   ...   \n",
       "10402  10402               128.0       7.558488             12.000000   \n",
       "10403  10403                30.0       1.743160             10.000000   \n",
       "10404  10404               196.0      30.920000             24.500000   \n",
       "10405  10405                38.0       1.553160             12.666667   \n",
       "10406  10406               288.0      24.655328             11.142857   \n",
       "\n",
       "       val_e_Average  atomicweight_Average  ionenergy_Average  \\\n",
       "0           4.800000             20.612526          11.088100   \n",
       "1           4.800000             20.298893          12.040830   \n",
       "2           5.600000             33.739258          12.086300   \n",
       "3           4.800000             20.213349          10.948500   \n",
       "4           4.800000             24.988133          11.824480   \n",
       "...              ...                   ...                ...   \n",
       "10402       4.000000             26.385218          11.330440   \n",
       "10403       5.333333             20.766935          14.163933   \n",
       "10404       5.500000             53.490297          10.074300   \n",
       "10405       4.666667             26.621687          11.290033   \n",
       "10406       4.571429             22.536126          10.960357   \n",
       "\n",
       "       el_neg_chi_Average  R_vdw_element_Average  R_cov_element_Average  \\\n",
       "0                2.766000               1.732000               0.860000   \n",
       "1                2.755000               1.631000               0.910000   \n",
       "2                2.828000               1.788000               0.864000   \n",
       "3                2.648000               1.626000               0.936000   \n",
       "4                2.766000               1.682000               0.896000   \n",
       "...                   ...                    ...                    ...   \n",
       "10402            2.644000               1.631000               0.892000   \n",
       "10403            3.090000               1.556667               0.866667   \n",
       "10404            2.295000               1.545000               1.120000   \n",
       "10405            2.743333               1.756667               0.980000   \n",
       "10406            2.792143               1.772857               0.940000   \n",
       "\n",
       "       zaratio_Average  density_Average  Hardness  \n",
       "0             0.496070          0.91457       6.0  \n",
       "1             0.492719          0.71760       6.5  \n",
       "2             0.481478          1.50633       2.5  \n",
       "3             0.489272          0.78937       6.0  \n",
       "4             0.492736          1.86481       6.0  \n",
       "...                ...              ...       ...  \n",
       "10402         0.496070          1.79607       4.0  \n",
       "10403         0.480390          0.81480       5.0  \n",
       "10404         0.469715          2.11540       1.8  \n",
       "10405         0.486507          0.77755       6.0  \n",
       "10406         0.493919          0.97737       6.5  \n",
       "\n",
       "[10407 rows x 13 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "973ed456-4338-4a32-be52-4e29daf90666",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_names = df.iloc[:,1:-1].columns.to_list()\n",
    "cat_names = []\n",
    "procs = [Normalize]\n",
    "splits = RandomSplitter()(range_of(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c53e814b-3324-4d93-9deb-762fc13319a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to = TabularPandas(df, procs, cat_names, cont_names, y_names=\"Hardness\", splits=splits, y_block=RegressionBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64bfb6a5-a9b9-4b83-b85d-ec3450b27bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192.000000</td>\n",
       "      <td>30.821995</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>119.629501</td>\n",
       "      <td>8.213150</td>\n",
       "      <td>2.298000</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>1.184000</td>\n",
       "      <td>0.467304</td>\n",
       "      <td>6.31300</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>10.207996</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>74.718704</td>\n",
       "      <td>11.177140</td>\n",
       "      <td>2.445000</td>\n",
       "      <td>1.765000</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.462985</td>\n",
       "      <td>5.09880</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>7.876748</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>22.212725</td>\n",
       "      <td>12.027800</td>\n",
       "      <td>2.727500</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.614430</td>\n",
       "      <td>1.49127</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.740168</td>\n",
       "      <td>4.666666</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>8.862139</td>\n",
       "      <td>13.652933</td>\n",
       "      <td>2.660000</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.825990</td>\n",
       "      <td>0.52252</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>415.000000</td>\n",
       "      <td>35.301964</td>\n",
       "      <td>10.878048</td>\n",
       "      <td>4.804878</td>\n",
       "      <td>20.994127</td>\n",
       "      <td>10.966795</td>\n",
       "      <td>2.715366</td>\n",
       "      <td>1.527073</td>\n",
       "      <td>0.851707</td>\n",
       "      <td>0.496533</td>\n",
       "      <td>0.75755</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>107.000000</td>\n",
       "      <td>12.417996</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>24.750879</td>\n",
       "      <td>11.330440</td>\n",
       "      <td>2.706000</td>\n",
       "      <td>1.907200</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.498666</td>\n",
       "      <td>1.00104</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>9.143996</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>56.980888</td>\n",
       "      <td>11.496917</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>1.742000</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.476095</td>\n",
       "      <td>4.90209</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>11.202328</td>\n",
       "      <td>19.333334</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>39.987667</td>\n",
       "      <td>11.556733</td>\n",
       "      <td>2.848333</td>\n",
       "      <td>1.756667</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.487833</td>\n",
       "      <td>1.69886</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>338.000000</td>\n",
       "      <td>36.095295</td>\n",
       "      <td>11.155556</td>\n",
       "      <td>4.444445</td>\n",
       "      <td>22.111242</td>\n",
       "      <td>11.189909</td>\n",
       "      <td>2.821111</td>\n",
       "      <td>1.724444</td>\n",
       "      <td>0.894444</td>\n",
       "      <td>0.490901</td>\n",
       "      <td>0.88120</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>544.400024</td>\n",
       "      <td>70.098297</td>\n",
       "      <td>5.428572</td>\n",
       "      <td>4.487783</td>\n",
       "      <td>11.990559</td>\n",
       "      <td>11.739439</td>\n",
       "      <td>2.719722</td>\n",
       "      <td>1.541520</td>\n",
       "      <td>0.736617</td>\n",
       "      <td>0.505030</td>\n",
       "      <td>0.68417</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = to.dataloaders(bs=64)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d43555b3-ece6-441d-833e-4d09fe2b3cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, loss_func=mae, metrics=mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9559bfc0-88d9-498f-b6fa-491686ae716f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.933384</td>\n",
       "      <td>0.972781</td>\n",
       "      <td>0.972781</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.949618</td>\n",
       "      <td>0.980479</td>\n",
       "      <td>0.980479</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.959424</td>\n",
       "      <td>0.967790</td>\n",
       "      <td>0.967790</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.963037</td>\n",
       "      <td>0.983448</td>\n",
       "      <td>0.983448</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.970716</td>\n",
       "      <td>0.997507</td>\n",
       "      <td>0.997507</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.957347</td>\n",
       "      <td>0.972419</td>\n",
       "      <td>0.972419</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.941777</td>\n",
       "      <td>0.967837</td>\n",
       "      <td>0.967837</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.919437</td>\n",
       "      <td>0.965841</td>\n",
       "      <td>0.965841</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.923242</td>\n",
       "      <td>0.965976</td>\n",
       "      <td>0.965976</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.929039</td>\n",
       "      <td>0.960516</td>\n",
       "      <td>0.960516</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.918482</td>\n",
       "      <td>0.960748</td>\n",
       "      <td>0.960748</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.907213</td>\n",
       "      <td>0.954441</td>\n",
       "      <td>0.954441</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "caf81ca3-186c-4226-bae6-fadaa14ebbbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Hardness_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.505964</td>\n",
       "      <td>-0.780840</td>\n",
       "      <td>-1.054044</td>\n",
       "      <td>-0.787431</td>\n",
       "      <td>-0.980573</td>\n",
       "      <td>0.230700</td>\n",
       "      <td>-0.165650</td>\n",
       "      <td>-1.196595</td>\n",
       "      <td>-1.077471</td>\n",
       "      <td>0.094029</td>\n",
       "      <td>-0.773102</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.934103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.043010</td>\n",
       "      <td>-0.183655</td>\n",
       "      <td>-0.347993</td>\n",
       "      <td>-0.211226</td>\n",
       "      <td>-0.307169</td>\n",
       "      <td>0.317069</td>\n",
       "      <td>0.234009</td>\n",
       "      <td>0.104811</td>\n",
       "      <td>-0.026249</td>\n",
       "      <td>0.088575</td>\n",
       "      <td>-0.581272</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.355187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.117870</td>\n",
       "      <td>0.849700</td>\n",
       "      <td>0.218120</td>\n",
       "      <td>1.133253</td>\n",
       "      <td>0.095063</td>\n",
       "      <td>0.417117</td>\n",
       "      <td>1.017420</td>\n",
       "      <td>-0.077661</td>\n",
       "      <td>-0.284444</td>\n",
       "      <td>-0.314919</td>\n",
       "      <td>0.083077</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4.502938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.447739</td>\n",
       "      <td>-0.638333</td>\n",
       "      <td>-0.672394</td>\n",
       "      <td>-0.787431</td>\n",
       "      <td>-0.671578</td>\n",
       "      <td>-0.875276</td>\n",
       "      <td>-0.926194</td>\n",
       "      <td>0.869129</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.085626</td>\n",
       "      <td>-0.621657</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.547757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.234319</td>\n",
       "      <td>1.598971</td>\n",
       "      <td>0.567966</td>\n",
       "      <td>0.653082</td>\n",
       "      <td>0.450177</td>\n",
       "      <td>-1.163475</td>\n",
       "      <td>-1.049223</td>\n",
       "      <td>0.694834</td>\n",
       "      <td>1.011141</td>\n",
       "      <td>-0.284306</td>\n",
       "      <td>1.516152</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.460598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.144140</td>\n",
       "      <td>-0.333482</td>\n",
       "      <td>-0.147627</td>\n",
       "      <td>0.172911</td>\n",
       "      <td>-0.155841</td>\n",
       "      <td>0.225482</td>\n",
       "      <td>0.440798</td>\n",
       "      <td>0.103090</td>\n",
       "      <td>0.121291</td>\n",
       "      <td>-0.167602</td>\n",
       "      <td>-0.256418</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.498179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.076281</td>\n",
       "      <td>-0.287019</td>\n",
       "      <td>-0.233498</td>\n",
       "      <td>-0.787431</td>\n",
       "      <td>-0.145162</td>\n",
       "      <td>0.322143</td>\n",
       "      <td>0.776829</td>\n",
       "      <td>-0.189554</td>\n",
       "      <td>-0.878292</td>\n",
       "      <td>1.522863</td>\n",
       "      <td>-0.581272</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.108125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.289701</td>\n",
       "      <td>1.425699</td>\n",
       "      <td>0.218120</td>\n",
       "      <td>0.172911</td>\n",
       "      <td>0.095063</td>\n",
       "      <td>-1.263882</td>\n",
       "      <td>-1.388486</td>\n",
       "      <td>0.765843</td>\n",
       "      <td>0.895875</td>\n",
       "      <td>-0.091578</td>\n",
       "      <td>-0.402097</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.848989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.056803</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>-0.233498</td>\n",
       "      <td>0.364980</td>\n",
       "      <td>-0.228382</td>\n",
       "      <td>0.280609</td>\n",
       "      <td>0.234009</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>-0.247559</td>\n",
       "      <td>-0.183493</td>\n",
       "      <td>0.334028</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.471454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3c9b4f71-e6dc-4fc9-abbb-93cce13f6f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm1d(input_size)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "            self.hidden_layers.append(nn.ReLU())\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "input_size = 12\n",
    "hidden_sizes = [16, 32]  \n",
    "output_size = 1 \n",
    "\n",
    "model = MLPModel(input_size, hidden_sizes, output_size)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e24f602d-dc29-4959-ac46-58f2204b0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "features = df.drop('Hardness', axis=1).values\n",
    "target = df['Hardness'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f6a7751f-e38c-423e-a238-e11ddb69645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "target_tensor = torch.tensor(target, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4bbe002a-a097-497b-8c38-ff25f1a06a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(features_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ac3023c5-9d9f-4472-8851-e6db7096f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b8a1660f-3310-4110-ae7d-bfacb8633d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for training and validation sets\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0db7f4a5-8a57-427b-93b6-0641f22847e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.2883\n",
      "Epoch [2/100], Loss: 1.1035\n",
      "Epoch [3/100], Loss: 1.0435\n",
      "Epoch [4/100], Loss: 1.0309\n",
      "Epoch [5/100], Loss: 1.0339\n",
      "Epoch [6/100], Loss: 1.0157\n",
      "Epoch [7/100], Loss: 1.0123\n",
      "Epoch [8/100], Loss: 1.0166\n",
      "Epoch [9/100], Loss: 1.0084\n",
      "Epoch [10/100], Loss: 1.0191\n",
      "Epoch [11/100], Loss: 1.0043\n",
      "Epoch [12/100], Loss: 1.0205\n",
      "Epoch [13/100], Loss: 1.0066\n",
      "Epoch [14/100], Loss: 1.0098\n",
      "Epoch [15/100], Loss: 1.0115\n",
      "Epoch [16/100], Loss: 1.0057\n",
      "Epoch [17/100], Loss: 1.0085\n",
      "Epoch [18/100], Loss: 1.0085\n",
      "Epoch [19/100], Loss: 1.0088\n",
      "Epoch [20/100], Loss: 1.0154\n",
      "Epoch [21/100], Loss: 1.0150\n",
      "Epoch [22/100], Loss: 1.0188\n",
      "Epoch [23/100], Loss: 1.0092\n",
      "Epoch [24/100], Loss: 1.0071\n",
      "Epoch [25/100], Loss: 1.0149\n",
      "Epoch [26/100], Loss: 1.0099\n",
      "Epoch [27/100], Loss: 0.9971\n",
      "Epoch [28/100], Loss: 0.9998\n",
      "Epoch [29/100], Loss: 1.0001\n",
      "Epoch [30/100], Loss: 1.0074\n",
      "Epoch [31/100], Loss: 0.9983\n",
      "Epoch [32/100], Loss: 1.0049\n",
      "Epoch [33/100], Loss: 1.0002\n",
      "Epoch [34/100], Loss: 0.9919\n",
      "Epoch [35/100], Loss: 0.9996\n",
      "Epoch [36/100], Loss: 0.9981\n",
      "Epoch [37/100], Loss: 0.9954\n",
      "Epoch [38/100], Loss: 1.0098\n",
      "Epoch [39/100], Loss: 0.9889\n",
      "Epoch [40/100], Loss: 0.9846\n",
      "Epoch [41/100], Loss: 0.9943\n",
      "Epoch [42/100], Loss: 0.9970\n",
      "Epoch [43/100], Loss: 1.0071\n",
      "Epoch [44/100], Loss: 1.0083\n",
      "Epoch [45/100], Loss: 0.9884\n",
      "Epoch [46/100], Loss: 0.9980\n",
      "Epoch [47/100], Loss: 1.0001\n",
      "Epoch [48/100], Loss: 0.9880\n",
      "Epoch [49/100], Loss: 0.9970\n",
      "Epoch [50/100], Loss: 1.0044\n",
      "Epoch [51/100], Loss: 0.9988\n",
      "Epoch [52/100], Loss: 0.9887\n",
      "Epoch [53/100], Loss: 0.9995\n",
      "Epoch [54/100], Loss: 0.9811\n",
      "Epoch [55/100], Loss: 0.9926\n",
      "Epoch [56/100], Loss: 0.9932\n",
      "Epoch [57/100], Loss: 0.9896\n",
      "Epoch [58/100], Loss: 0.9887\n",
      "Epoch [59/100], Loss: 0.9932\n",
      "Epoch [60/100], Loss: 1.0001\n",
      "Epoch [61/100], Loss: 0.9914\n",
      "Epoch [62/100], Loss: 0.9884\n",
      "Epoch [63/100], Loss: 0.9932\n",
      "Epoch [64/100], Loss: 0.9964\n",
      "Epoch [65/100], Loss: 0.9803\n",
      "Epoch [66/100], Loss: 0.9797\n",
      "Epoch [67/100], Loss: 0.9819\n",
      "Epoch [68/100], Loss: 0.9988\n",
      "Epoch [69/100], Loss: 0.9979\n",
      "Epoch [70/100], Loss: 0.9905\n",
      "Epoch [71/100], Loss: 0.9872\n",
      "Epoch [72/100], Loss: 0.9929\n",
      "Epoch [73/100], Loss: 0.9927\n",
      "Epoch [74/100], Loss: 0.9951\n",
      "Epoch [75/100], Loss: 0.9916\n",
      "Epoch [76/100], Loss: 0.9962\n",
      "Epoch [77/100], Loss: 0.9873\n",
      "Epoch [78/100], Loss: 0.9960\n",
      "Epoch [79/100], Loss: 0.9934\n",
      "Epoch [80/100], Loss: 0.9957\n",
      "Epoch [81/100], Loss: 0.9953\n",
      "Epoch [82/100], Loss: 0.9845\n",
      "Epoch [83/100], Loss: 0.9876\n",
      "Epoch [84/100], Loss: 0.9908\n",
      "Epoch [85/100], Loss: 0.9965\n",
      "Epoch [86/100], Loss: 0.9894\n",
      "Epoch [87/100], Loss: 0.9866\n",
      "Epoch [88/100], Loss: 0.9974\n",
      "Epoch [89/100], Loss: 0.9835\n",
      "Epoch [90/100], Loss: 0.9863\n",
      "Epoch [91/100], Loss: 0.9886\n",
      "Epoch [92/100], Loss: 0.9948\n",
      "Epoch [93/100], Loss: 0.9798\n",
      "Epoch [94/100], Loss: 0.9902\n",
      "Epoch [95/100], Loss: 0.9884\n",
      "Epoch [96/100], Loss: 0.9981\n",
      "Epoch [97/100], Loss: 0.9905\n",
      "Epoch [98/100], Loss: 0.9917\n",
      "Epoch [99/100], Loss: 0.9864\n",
      "Epoch [100/100], Loss: 0.9888\n"
     ]
    }
   ],
   "source": [
    "# Rest of the code for training loop and evaluation\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_features, batch_target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_features)\n",
    "        loss = criterion(output, batch_target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b1450dcf-44c1-4766-96c9-fc43c1e47016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.9999\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_target in val_loader:\n",
    "        output = model(batch_features)\n",
    "        loss = criterion(output, batch_target)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "average_val_loss = val_loss / len(val_loader)\n",
    "print(f\"Validation Loss: {average_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab26601",
   "metadata": {},
   "source": [
    "## Submitting to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf2ea997-1fcd-406b-9662-58309f994b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.read_csv(path/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "599e5063-f6d5-40b4-a213-2ab7749d3228",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = pd.read_csv(path/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5559067-1234-44af-a90c-f04fdb583d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss['Hardness'] = pipe.predict(tst.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "480b7cae-7c65-49a9-81e9-1fd772ac76f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,Hardness\n",
      "10407,2.2447038862580264\n",
      "10408,2.9816768410094707\n",
      "10409,6.057493409630426\n",
      "10410,4.0252023999737645\n",
      "10411,6.180580306667615\n",
      "10412,4.6798035133943365\n",
      "10413,3.7570595169337735\n",
      "10414,5.385486430590966\n",
      "10415,3.173753209604238\n"
     ]
    }
   ],
   "source": [
    "ss.to_csv('subm.csv', index=False)\n",
    "!head subm.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed52342c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 164k/164k [00:00<00:00, 185kB/s]\n"
     ]
    }
   ],
   "source": [
    "if not iskaggle:\n",
    "    from kaggle import api\n",
    "    api.competition_submit_cli('subm.csv', 'MLP', comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04efcc0",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a972c10e",
   "metadata": {},
   "source": [
    "## Addendum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2148d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not iskaggle:\n",
    "    push_notebook('xy', 'mock-first-steps-road-to-the-top-part-1',\n",
    "                  title='mock First Steps: Road to the Top, Part 1',\n",
    "                  file='mock-first-steps-road-to-the-top-part-1.ipynb',\n",
    "                  competition=comp, private=False, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e901eb-2691-4216-a8f5-014ad9ea96f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
